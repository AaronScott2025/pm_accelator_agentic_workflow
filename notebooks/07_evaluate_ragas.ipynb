{"cells":[{"cell_type":"markdown","metadata":{},"source":["# RAGAS Evaluation Notebook\n","\n","This notebook demonstrates evaluating retrieval quality using [RAGAS](https://github.com/explodinggradients/ragas).\n","It assumes you have already ingested data (03_ingest_index.ipynb) and optionally run comparisons (06_end_to_end_comparison.ipynb).\n","\n","Prerequisites (one-time):\n","- Install: `poetry run pip install ragas datasets evaluate`\n","- Ensure `.env` has `OPENAI_API_KEY` set (needed for some RAGAS metrics).\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from __future__ import annotations\n","\n","from typing import List, Dict\n","\n","from ai_interviewer_pm.retrieval.vectorstore import similarity_search, build_vectorstore\n","from ai_interviewer_pm.ingestion.chunkers import TimestampChunker\n","from ai_interviewer_pm.settings import settings\n","from pathlib import Path\n","\n","# Small demo dataset assembled from local data/.\n","texts = [p.read_text(encoding='utf-8') for p in Path(settings.data_dir).glob('*.vtt')]\n","if not texts:\n","    print('No .vtt files in data/. Add files and re-run ingestion for meaningful RAGAS evaluation.')\n","\n","chunker = TimestampChunker()\n","chunks, metas = [], []\n","for t in texts:\n","    cs = chunker.split(t, metadata={'chunker': 'timestamp'})\n","    chunks.extend([c.text for c in cs])\n","    metas.extend([c.metadata for c in cs])\n","\n","store = None\n","if chunks:\n","    store = build_vectorstore(chunks, metas)\n","store\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Build a toy QA dataset for RAGAS. In a real setup, prepare a curated dataset.\n","examples: List[Dict[str, str]] = []\n","queries = [\n","    'How to handle stakeholder conflict?',\n","    'How to structure an interview answer using STAR?',\n","]\n","if store is not None:\n","    for q in queries:\n","        hits = similarity_search(store, q, k=3)\n","        contexts = [d for (d, _m, _s) in hits]\n","        examples.append({'question': q, 'contexts': contexts, 'ground_truth': ''})\n","examples\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# RAGAS evaluation (requires ragas installed)\n","# Metrics: Answer Relevancy, Faithfulness, Context Precision/Recall\n","try:\n","    from ragas import evaluate\n","    from ragas.metrics import (\n","        answer_relevancy, faithfulness, context_precision, context_recall\n","    )\n","    import datasets as hfds\n","\n","    if examples:\n","        ds = hfds.Dataset.from_list(examples)\n","        result = evaluate(\n","            ds,\n","            metrics=[answer_relevancy, faithfulness, context_precision, context_recall],\n","        )\n","        print(result)\n","    else:\n","        print('No examples assembled for RAGAS. Ensure data is ingested and queries return contexts.')\n","except Exception as e:\n","    print('RAGAS not installed or failed to run:', e)\n"]}],"metadata":{"kernelspec":{"display_name":"Python (ai-interviewer-pm)","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11"}},"nbformat":4,"nbformat_minor":5}
